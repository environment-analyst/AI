{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 06.Transfer Laerning with TensorFlow Part 3 : Scaling up( Food vision mini)"
      ],
      "metadata": {
        "id": "zRIeP_0Y6T1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What we're going to cover\n",
        "\n",
        "We're oging to go throguh the follow with TensorFlow:\n",
        " - Downloading and preparing 10% of the Food101 data(10% of trainig data)\n",
        " - Training a feature extraction transfer learnin model on 10% of the Fooe101 training data\n",
        " - Fine-tuning our feature extraction model\n",
        " - Saving and loaded our traned model\n",
        " - Evaluating the performance of our Food Vision model trained on 10% of the training data\n",
        "    - Finding our model's most wrong predicions\n",
        "- making predicions with our Food Vision model on cumstom image of food"
      ],
      "metadata": {
        "id": "poY6y67N6oA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU?\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "0mcVl6MH-Z41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6480bfb3-58bc-4fc7-8ae1-53754d1d79b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "lQsGjHSx-hyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6672ea0f-30b8-470b-d51b-d9873c8c06f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run (end-to-end): 2025-06-02 07:09:58.205157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create helper functions"
      ],
      "metadata": {
        "id": "v_mAGO6b-pJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper functions file\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "h76os06P-w2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6638c771-f705-4174-ad0f-e89a0fc0b0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 07:09:58--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-06-02 07:09:58 (78.2 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 101 Food Classes: Working with less data"
      ],
      "metadata": {
        "id": "6UD2dLkf-1kJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and preprocessing the data"
      ],
      "metadata": {
        "id": "RQgchR3f-52H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data from Google Storage (already preformatted)\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test\"\n"
      ],
      "metadata": {
        "id": "4-CBFTsx--jk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "5cd90588-186c-4e21-f172-ae6ad0de0c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-02 07:09:58--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.207, 142.250.141.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip.1’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   189MB/s    in 15s     \n",
            "\n",
            "2025-06-02 07:10:13 (102 MB/s) - ‘101_food_classes_10_percent.zip.1’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'unzip_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-afa61830d1ac>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Download data from Google Storage (already preformatted)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munzip_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"101_food_classes_10_percent.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"101_food_classes_10_percent/train/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'unzip_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images/classes are there?\n",
        "walk_through_dir(\"101_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "rtXiI4Sb_OlC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIAE = (224, 224)\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir, label_mode = \"categorical\",\n",
        "                                                                                image_size = IMG_SIZE)\n",
        "test_data=tf.keras.preprocessing.image_dataset_from_directory(test_dir, label_mode = \"categorical\",\n",
        "                                                              image_size=IMG_SIZE,\n",
        "                                                              shuffle=False)\n"
      ],
      "metadata": {
        "id": "DjpWRk_h_YT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a big dog model with transfer learning on 10% ot 101 food classes"
      ],
      "metadata": {
        "id": "IBwth4mOAG5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create checkpoint callback to save model for later use\n",
        "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n",
        "checkpoint_callback = tf.keras.callbacks.Modelcheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only = True, # save only the model weights\n",
        "                                                         monitor = \"val_accuracy\", # save the model weigghts which score the best validation accuracy\n",
        "                                                         save_best_only = True) # only keep the best model weights on file (delete the rest)"
      ],
      "metadata": {
        "id": "CsAm3qrgALjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the required modules for model creation\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentaion = Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2).\n",
        "\n",
        "], name = \"data_augmentation\")"
      ],
      "metadata": {
        "id": "mEIDOKZMAxfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup base model and freeae its layers (this will extract features)\n",
        "base_model =tf.keras.applications.efficientnet.EfficientNetB0(include_top=Fasle)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Setup model architerue with trainable top layers\n",
        "inputs = layers.Input(shape=(224, 224, 3), name = \"input_layer\" )# shape of input image\n",
        "X = data_augementaion(inputs) # augment images ( only happens during training)\n",
        "x = base_model(x, trainig = False) # put the base model in inference mode so we can useit to extract feature without update the weights\n",
        "x = layers.GlobalAveragePooling2D(name = \"global_average_pooling\")(x) # poolt the outputs ot the base model\n",
        "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation=\"softmax\", name = \"output_layer\")(x) # same number of outputs as classes\n",
        "model = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "tUBRvFQBBTpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ZHxRiADbDPPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "model.compile(loss = \"cateforical_crossentropy\",\n",
        "              optimizers = tf.keras.optimizers.Adam().\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "# fit\n",
        "history_all_classes_10_percent = model.fit(train_data_all_10_percent,\n",
        "                                           epochs = 5, # fit for epochs to keep experiments quick\n",
        "                                           validation_data = test_data,\n",
        "                                           validation_steps = int(0.15 * len(test_data)),\n",
        "                                           callbacks = [checkpoint_callback])"
      ],
      "metadata": {
        "id": "RvJkuXSoDS2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "results_feature_extraction_model = model.evaluate(test_data)\n",
        "results_feature_extraction_model"
      ],
      "metadata": {
        "id": "A3ElnPVJD13b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(history_all_classes_10_percent)"
      ],
      "metadata": {
        "id": "4r7MKX5qEGCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tunning"
      ],
      "metadata": {
        "id": "ZlLfYpqBEMTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all ot the layer in the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze every layer except for the last 5\n",
        "for layer in base_model.layer[:-5]:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "yNWo0XR5EW9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompile model with lower learning rate\n",
        "model.compile(loss='categoricla_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(1e-4), # 10x lwer learning rate than default\n",
        "              metrics =['accuracy'])"
      ],
      "metadata": {
        "id": "i_aESx6SEkzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What layers in the model are trainable?\n",
        "for layer in model.layers:\n",
        "    print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "oq2ytkG7E58F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check which layers are trainable\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "    print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "f3mbxz6pFB-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-Tune for 5 more epochs\n",
        "fine_tune_epochs = 10 # model hase already done 5 epochs, this is the total number of epochs we're after (5+5=10)\n",
        "\n",
        "history_all_classes_10_percent_fine_tune = model.fit(train_data_all_10_percent,\n",
        "                                                     epochs = fine_tune_epochs,\n",
        "                                                     valdiation_data = test_data,\n",
        "                                                     validation_steps = int(0.15 * len(test_data)), # validation on 15% of the test data\n",
        "                                                     intial_epoch = history_all_classes_10_percent.epoch[-1])# start from previous last epoch"
      ],
      "metadata": {
        "id": "ld2gXcztFMxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate fine-tunned model on the whole test dataset\n",
        "results_all_classes_10_percent_fine_tune = model.evaluate(test_data)\n",
        "results_all_classes_10_percent_fine_tune"
      ],
      "metadata": {
        "id": "7SkYFidfF5qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Saving our trained model\n"
      ],
      "metadata": {
        "id": "7a5kaufNGG97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## save model to drive so it can be used later\n",
        "model.save(\"drive/My Drvie/tensorflow_course/101_food_class_10_percent_saved_big_dog_model\")"
      ],
      "metadata": {
        "id": "c38zQBvgGOQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the performance of the big dog model across all different classes"
      ],
      "metadata": {
        "id": "NAEh5j58GcTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip\n",
        "saved_model_path = \"06_101_food_class_10_percent_saved_big_dog_model.zip\"\n",
        "unzip_data(saved_model_path)\n",
        "\n",
        "model = tf.keras.models.load_model(saved_model_path.split(\".\")[0]) # don't include \".zip\" in loaded model path"
      ],
      "metadata": {
        "id": "7UYFyywKGiW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see if loaded model is a trained model\n",
        "loaded_loss, loaded_accuracy = model.evaluate(test_data)\n",
        "loaded_loss, loaded_accuracy"
      ],
      "metadata": {
        "id": "5tzWYUxkG5Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "pred_probs = model.predict(test_data, verbose = 1) # set verbosity to see how long it will take"
      ],
      "metadata": {
        "id": "2IuppO4aHIGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many predicions are there?\n",
        "len(pred_probs)"
      ],
      "metadata": {
        "id": "7tVgpee1HTpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the shape of our predictions?\n",
        "pred_probs.shape"
      ],
      "metadata": {
        "id": "KcGA6y_dHZTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How do they look?\n",
        "pred_probs[:10]"
      ],
      "metadata": {
        "id": "F3JTbJbUHePO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we get one predition probability per class\n",
        "print(f\"Number of predictions probabilities for sample 0: {len(pred_probs[0])}\")\n",
        "print(f\"What prediction probability sample 0 looks like: \\n {pred_probs[0]}\")\n",
        "print(f\"The class with the highest predicted probability by the model for sample 0: {pred_probs[0].argmax()}\")"
      ],
      "metadata": {
        "id": "nicGJeHaHifo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class predicions of each label\n",
        "pred_classes = pred_probs.srgmax(axis = 1)\n",
        "\n",
        "# How do thdy look?\n",
        "pred_classes[:10]"
      ],
      "metadata": {
        "id": "DtHiAvdPID8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_labels = []\n",
        "for images, labels in test_data.unbatch(): # unbatch the test data and get images and labels\n",
        "    y_labels.append(labels.numpy().argmax()) # append the index which has the largest value (labels are one-hot)\n",
        "y_labels[:10] # check what they look like (unshuffled)"
      ],
      "metadata": {
        "id": "FePD8gQCtmDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many labels are there ? (should be the same as how many predictions probabilites we have)\n",
        "len(y_labels)"
      ],
      "metadata": {
        "id": "vHOdmYcJuRHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating our models predictions"
      ],
      "metadata": {
        "id": "-X6r8isDucBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get accuracy score by comparing predicted classes to ground truth labels\n",
        "from sklearn.metrics import accuracy_score\n",
        "sklearn_accuracy = accrucay_scroe(y_labels, pred_classes)\n",
        "sklearn_accuracy"
      ],
      "metadata": {
        "id": "H2CO2L9lufTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does the evaluate method compare to the Scikit-learn measured accracy?\n",
        "import numpy as np\n",
        "print(f\"Close?{np.isclose(loaded_accuracy, sklearn_accuracy)} | Difference : {loaded_accuracy - sklearn_accuracy}\")"
      ],
      "metadata": {
        "id": "TN3DT9CjuunY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import make_confusion_matrix"
      ],
      "metadata": {
        "id": "ND2N1evxu_1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10,10), test_size =15, norm=False, savefig=False):\n",
        "\n",
        "    # Create the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_norm  = cm.astype(\"float\") / cm.sum(axis = 1)[:, np.newaxis] # normalize it\n",
        "    n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "    # plot the figure and mske it pretty\n",
        "    fig, ax= plt.subplots(figsize = figsize)\n",
        "    cax = ax.matshow(cm, cmap = plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "    fig.colorbas(cax)\n",
        "\n",
        "    # Are there a list of classes?\n",
        "    if classes:\n",
        "        labels = classes\n",
        "    else:\n",
        "        labels = np.arange(cm.shape[0])\n",
        "\n",
        "    ax.set(title = \"Confusion Matrix\",\n",
        "           xlabel = \"Predicted label\",\n",
        "           ylabel = \"True label\",\n",
        "           xticks = np.arnage(n_classes), # create enogh axis slots for each class\n",
        "           yticks = np.arange(n_classes),\n",
        "           xticklabels = labels, # axes will labeled with class name (if they exist) or ints\n",
        "           yticklabels = labels)\n",
        "\n",
        "    # Make x-axis labels appear on bottom\n",
        "    ax.xaxis.set_label_position(\"botton\")\n",
        "    ax.xaxis.tick_bottom()\n",
        "\n",
        "    ### Added : Rotate xticks for readability & increate font siae (requured due to such a large confusion matrix)\n",
        "    plt.xticks(rotation=70, fontsize = test_size)\n",
        "    plt.yticks(fontsize = test_size)\n",
        "\n",
        "    # Set the threshold for different colors\n",
        "    threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "     # Plot the test on each cell\n",
        "     for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if norm:\n",
        "            plt.text(j, i, f\"{cm[i, j]*100 :.1f}%\",\n",
        "                     horizontalaignment=\"center\",\n",
        "                     color = \"white\" if cm[i,j] > threshold else \"black\",\n",
        "                     size = test_size)\n",
        "        else:\n",
        "            plt.text(j, i, f\"{cm[i, j]}\",\n",
        "                    horizontalalignment = \"center\",\n",
        "                    color = \"white\" if cm[i,j] > threshold else \"black\",\n",
        "                    size = text_size)\n",
        "\n",
        "    # Save the figure to the current working directory\n",
        "    if savefig:\n",
        "        fig.savefig(\"confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "FqslPG_LvEMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names\n",
        "class_name = test_data.class_names\n",
        "class_name[:10]"
      ],
      "metadata": {
        "id": "OTzpLAWgyXwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a confusion matrix with all 25250 prdicions, ground truth labels and 101 calsses\n",
        "make_confusion_matrix(y_true = y_labels,\n",
        "                      y_pred=pred_classes,\n",
        "                      classes = class_names,\n",
        "                      figsize = (100,100),\n",
        "                      text_size = 20,\n",
        "                      norm = False,\n",
        "                      savefig = True)"
      ],
      "metadata": {
        "id": "vENkXG53yloI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_labels, pred_classes))"
      ],
      "metadata": {
        "id": "mYa-0LeEzFdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary ot the classification report\n",
        "classification_report_dict = classification_report(y_labels, pred_classes, output_dict = True)\n",
        "classification_report_dict"
      ],
      "metadata": {
        "id": "mN0QZa0MzV9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty dictionary\n",
        "class_f1_scores = {}\n",
        "# Loop through classification reprot items\n",
        "for k, v in classification_reprot_dict.items():\n",
        "    if k == \"accuracy\": # stop once we get to accuracy key\n",
        "        break\n",
        "    else:\n",
        "        # Append class names and f1-scored to new dictionary\n",
        "        class_f1_scores[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_scores"
      ],
      "metadata": {
        "id": "lsYhEnPCzwo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn f1-score into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_score = pd.DataFrame({\"class_name\" : list(class_f1_scores.keys()),\n",
        "                         \"f1-score\": list(class_f1_scores.values())}).sort_values(\"f1-score\", ascending = False)\n",
        "                         f1_score.head()"
      ],
      "metadata": {
        "id": "GLBsat-Q0X0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplot(figsize = (12,25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1_score\"].values)\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_ytickslabels(list(f1_scores[\"class_name\"]))\n",
        "ax.set_xlabel(\"f1-score\")\n",
        "ax.set_title(\"F1-scores for 10 Different Classes\")\n",
        "ax.invert_yaxis(); # reverse the order\n",
        "\n",
        "def autolabel(rects) :\n",
        "\n",
        "    for rect in rects:\n",
        "       width = rect.get_width()\n",
        "       ax.test(1.03*width, rect.get_Y() + rect.get_height()/1.5,\n",
        "               f\"width:.2f\",\n",
        "               ha='center',\n",
        "               va = \"bottom\")\n",
        "autolabel(scores)"
      ],
      "metadata": {
        "id": "bGGqPtH303hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing predictions on thest images"
      ],
      "metadata": {
        "id": "luG2UcBS15kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_prep_image(filename, img_shape = 224, scale=True):\n",
        "\n",
        "    # Read in the image\n",
        "    img = tf.io.read_file(filename)\n",
        "\n",
        "    # Decode it into a tensor\n",
        "    img = tf.io.decode_image(img)\n",
        "\n",
        "    # Resize the image\n",
        "    img = tf.image.resize(img, [img_shape, img_shape])\n",
        "    if scale:\n",
        "        # Rescale the image( get all values between 1 and 1)\n",
        "        return img/255.\n",
        "    else:\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "XsAp6t4gHXAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make preds on a series of random iamges\n",
        "import os\n",
        "import random\n",
        "\n",
        "plt.figure(figsize=(17, 10))\n",
        "for i in range(3):\n",
        "    # Choose a random image from a random class\n",
        "    class_name = random.choice(class_names)\n",
        "    filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n",
        "    filepath = test_dir + class_name + \"/\" filename\n",
        "\n",
        "    # Load the image and make predictions\n",
        "    img = load_and_prep_image(filepath, scale = False) # don't scale images for Efficient predictions\n",
        "    pred_prob = model.predict(tf.expand_dims(img, axis = 0)) # model accepts tensors of shape [ None, 224, 224, 3]\n",
        "    pred_class = class_name[pred_prob, argmax()] # find the predicted class\n",
        "\n",
        "    # Plot the iamge(s)\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow(img/255.)\n",
        "    if class_name == pred_class: # change the color of the test based on whether prediction is right or wrong\n",
        "        title_color= \"g\"\n",
        "    else:\n",
        "        title_color =\"r\"\n",
        "    plt.title(f\"acrual : {class_name}, pred  : {pred_class}, prop : {pred_prob.max():.2f}\", c=title_color)\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "A2nlPMgQ252i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get the filenames of all of our test data\n",
        "\n",
        "filepaths  = []\n",
        "for filepath in test_data.list_files(\"101_food_classes_10_percent/test/*/*.jpg\",\n",
        "                                     shuffle = False):\n",
        "    filepaths.append(filepath.numpy())\n",
        "filepaths[:10]\n"
      ],
      "metadata": {
        "id": "rGarKJPe4e8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a dataframe out of current predicion data for analysis\n",
        "import pandas as pd\n",
        "pred_df = pd.DataFrame({\"img_path\": filepaths,\n",
        "                        \"y_true\": y_labels,\n",
        "                        \"y_pred\" : pred_classes,\n",
        "                        \"pred_conf\" : pred_probs.mas(axs = 1), # get the maximum prediction probability value\n",
        "                        \"y_true_classname\":[class_names[i] for i in y_labels],\n",
        "                        \"y_pred_classname\" : [class_names[i] for i in pred_classes]})\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "EkHx1D1-5Rj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Is the prediction correct?\n",
        "pred_df[\"pred_correct\"] = pred_dr[\"y_true\"] ==  pred_df[\"y_pred\"]\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "wvVVJvHo6HhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Get the top 100 wrong examples\n",
        "top_100_wrong  = pred_df[pred_df[\"pred_correct\"] == False].sort_values(\"pred_conf\", ascending = False)[:100]\n",
        "top_100_wrong.head(20)"
      ],
      "metadata": {
        "id": "ohk0tWzZ6RMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Visualize some of the most wrong examples\n",
        "image_to_view = 9\n",
        "start_index = 10 # change the start index to view more\n",
        "plt.figure(figsize = (15, 10))\n",
        "for i, fow in enumerate(top_100_wrong[start_index: start_index + images_to_view].itertuples()):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    img = load_and_prep_image(row[1], scale = True)\n",
        "    -, -,-,-, pred_prob, y_true, y_pred, - = row # only interested in a fes parameters of each row\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"actual : {y_true}, pred : {y_pred} \\n prob : {pred_prob:.2f}\")\n",
        "    plt.axis(Flase)"
      ],
      "metadata": {
        "id": "KqayKTVE6kRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test out the big dog model on test images as well as custom images of food\n"
      ],
      "metadata": {
        "id": "1Hktx5_E7iJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some custom images from Google Storage\n",
        "# Note: you can upload your own custom images to Google Colab using the \"upload\" button in the Files tab\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip\n",
        "\n",
        "unzip_data(\"custom_food_images.zip\")"
      ],
      "metadata": {
        "id": "ppNRr4pz78LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom food image filepaths\n",
        "custom_food_images = [\"custom_food_images/\" + img_path for img_path in os.listdir(\"custom_food_images\")]\n",
        "custome_food_images"
      ],
      "metadata": {
        "id": "dDQ6m_iB8A8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predicitions on custom food images\n",
        "for img in custom_food_images:\n",
        "    img = load_and_prep_image(img, scale = Flase) # Load in target image and turn it into\n",
        "    pred_prob = model.predict(tf.exand_dims(img, axis = 0l))\n",
        "    pred_calss = class_name[pred_prob.argmax()] # find the predited class label\n",
        "    # Plot the image with appropriate annotations\n",
        "    plt.figure()\n",
        "    plt.imshow(img/255.)\n",
        "    plt.title(f\"pred : {pred_class}, prob : {pred_prob.max():.2f}\")\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "4p2674d08QlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uEthbduN-ozI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}